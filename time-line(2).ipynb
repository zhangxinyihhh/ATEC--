{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"D:/workspace/mayi/data/atec_anti_fraud_train.csv\")\n",
    "data_test = pd.read_csv(\"D:/workspace/mayi/data/atec_anti_fraud_test_b.csv\")\n",
    "# unlabel = data_train[data_train.label == -1].drop(['id'], axis = 1)\n",
    "# data_train = data_train[data_train.label != -1].drop(['id'], axis = 1).sort_values(by = 'date')\n",
    "# unlabel = pd.read_csv(\"F:/contest/ATEC/unlabel.csv\")\n",
    "data_train = data_train.drop(['id'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = data_train.sort_values(by = 'date')\n",
    "\n",
    "\n",
    "data_train['ifexist5'] = np.where(data_train.f5.isnull() == True, -1, 1 )\n",
    "data_train['ifexist20-23'] = np.where(data_train.f20.isnull() == True, -1, 1 )\n",
    "data_train['ifexist24-27'] = np.where(data_train.f24.isnull() == True, -1, 1)\n",
    "data_train['ifexist28-31'] = np.where(data_train.f28.isnull() == True, -1, 1)\n",
    "data_train['ifexist32-35'] = np.where(data_train.f32.isnull() == True, -1, 1)\n",
    "data_train['ifexist36-47'] = np.where(data_train.f36.isnull() == True, -1, 1)\n",
    "data_train['ifexist48-51'] = np.where(data_train.f48.isnull() == True, -1, 1)\n",
    "data_train['ifexist52-53'] = np.where(data_train.f52.isnull() == True, -1, 1)\n",
    "data_train['ifexist54-63'] = np.where(data_train.f54.isnull() == True, -1, 1)\n",
    "data_train['ifexist64-71'] = np.where(data_train.f64.isnull() == True, -1, 1)\n",
    "data_train['ifexist72-75'] = np.where(data_train.f72.isnull() == True, -1, 1)\n",
    "data_train['ifexist76-101'] = np.where(data_train.f76.isnull() == True, -1, 1)\n",
    "data_train['ifexist102-106'] = np.where(data_train.f102.isnull() == True, -1, 1)\n",
    "data_train['ifexist107-110'] = np.where(data_train.f107.isnull() == True, -1, 1)\n",
    "data_train['ifexist111-154'] = np.where(data_train.f111.isnull() == True, -1, 1)\n",
    "data_train['ifexist155-160'] = np.where(data_train.f155.isnull() == True, -1, 1)\n",
    "data_train['ifexist161-165'] = np.where(data_train.f161.isnull() == True, -1, 1)\n",
    "data_train['ifexist166-210'] = np.where(data_train.f166.isnull() == True, -1, 1)\n",
    "data_train['ifexist211-253'] = np.where(data_train.f211.isnull() == True, -1, 1)\n",
    "data_train['ifexist254-277'] = np.where(data_train.f254.isnull() == True, -1, 1)\n",
    "data_train['ifexist278-297'] = np.where(data_train.f278.isnull() == True, -1, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_test= data_test.sort_values(by = 'date')\n",
    "dt = data_train\n",
    "data_train = data_test\n",
    "data_train['ifexist5'] = np.where(data_train.f5.isnull() == True, -1, 1 )\n",
    "data_train['ifexist20-23'] = np.where(data_train.f20.isnull() == True, -1, 1 )\n",
    "data_train['ifexist24-27'] = np.where(data_train.f24.isnull() == True, -1, 1)\n",
    "data_train['ifexist28-31'] = np.where(data_train.f28.isnull() == True, -1, 1)\n",
    "data_train['ifexist32-35'] = np.where(data_train.f32.isnull() == True, -1, 1)\n",
    "data_train['ifexist36-47'] = np.where(data_train.f36.isnull() == True, -1, 1)\n",
    "data_train['ifexist48-51'] = np.where(data_train.f48.isnull() == True, -1, 1)\n",
    "data_train['ifexist52-53'] = np.where(data_train.f52.isnull() == True, -1, 1)\n",
    "data_train['ifexist54-63'] = np.where(data_train.f54.isnull() == True, -1, 1)\n",
    "data_train['ifexist64-71'] = np.where(data_train.f64.isnull() == True, -1, 1)\n",
    "data_train['ifexist72-75'] = np.where(data_train.f72.isnull() == True, -1, 1)\n",
    "data_train['ifexist76-101'] = np.where(data_train.f76.isnull() == True, -1, 1)\n",
    "data_train['ifexist102-106'] = np.where(data_train.f102.isnull() == True, -1, 1)\n",
    "data_train['ifexist107-110'] = np.where(data_train.f107.isnull() == True, -1, 1)\n",
    "data_train['ifexist111-154'] = np.where(data_train.f111.isnull() == True, -1, 1)\n",
    "data_train['ifexist155-160'] = np.where(data_train.f155.isnull() == True, -1, 1)\n",
    "data_train['ifexist161-165'] = np.where(data_train.f161.isnull() == True, -1, 1)\n",
    "data_train['ifexist166-210'] = np.where(data_train.f166.isnull() == True, -1, 1)\n",
    "data_train['ifexist211-253'] = np.where(data_train.f211.isnull() == True, -1, 1)\n",
    "data_train['ifexist254-277'] = np.where(data_train.f254.isnull() == True, -1, 1)\n",
    "data_train['ifexist278-297'] = np.where(data_train.f278.isnull() == True, -1, 1)\n",
    "\n",
    "data_test = data_train\n",
    "data_train = dt\n",
    "del dt\n",
    "\n",
    "# data_train = unlabel\n",
    "# data_train['ifexist5'] = np.where(data_train.f5.isnull() == True, -1, 1 )\n",
    "# data_train['ifexist20-23'] = np.where(data_train.f20.isnull() == True, -1, 1 )\n",
    "# data_train['ifexist24-27'] = np.where(data_train.f24.isnull() == True, -1, 1)\n",
    "# data_train['ifexist28-31'] = np.where(data_train.f28.isnull() == True, -1, 1)\n",
    "# data_train['ifexist32-35'] = np.where(data_train.f32.isnull() == True, -1, 1)\n",
    "# data_train['ifexist36-47'] = np.where(data_train.f36.isnull() == True, -1, 1)\n",
    "# data_train['ifexist48-51'] = np.where(data_train.f48.isnull() == True, -1, 1)\n",
    "# data_train['ifexist52-53'] = np.where(data_train.f52.isnull() == True, -1, 1)\n",
    "# data_train['ifexist54-63'] = np.where(data_train.f54.isnull() == True, -1, 1)\n",
    "# data_train['ifexist64-71'] = np.where(data_train.f64.isnull() == True, -1, 1)\n",
    "# data_train['ifexist72-75'] = np.where(data_train.f72.isnull() == True, -1, 1)\n",
    "# data_train['ifexist76-101'] = np.where(data_train.f76.isnull() == True, -1, 1)\n",
    "# data_train['ifexist102-106'] = np.where(data_train.f102.isnull() == True, -1, 1)\n",
    "# data_train['ifexist107-110'] = np.where(data_train.f107.isnull() == True, -1, 1)\n",
    "# data_train['ifexist111-154'] = np.where(data_train.f111.isnull() == True, -1, 1)\n",
    "# data_train['ifexist155-160'] = np.where(data_train.f155.isnull() == True, -1, 1)\n",
    "# data_train['ifexist161-165'] = np.where(data_train.f161.isnull() == True, -1, 1)\n",
    "# data_train['ifexist166-210'] = np.where(data_train.f166.isnull() == True, -1, 1)\n",
    "# data_train['ifexist211-253'] = np.where(data_train.f211.isnull() == True, -1, 1)\n",
    "# data_train['ifexist254-277'] = np.where(data_train.f254.isnull() == True, -1, 1)\n",
    "# data_train['ifexist278-297'] = np.where(data_train.f278.isnull() == True, -1, 1)\n",
    "# data_train = dt\n",
    "# del dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(data_train.columns)[2:]\n",
    "giveup =[]\n",
    "for i in col:\n",
    "#     if data_train[i].isnull().sum() > 250000 :\n",
    "    if data_train[i].isnull().sum() > 200000:\n",
    "        giveup.append(i)\n",
    "        \n",
    "col1 = [i for i in col if i not in giveup]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unlabel = data_train[data_train.label == -1]\n",
    "# data_train = data_train[data_train.label != -1]\n",
    "# data_train = data_train[data_train.date < 20171001]\n",
    "data_train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "lg = lgb.LGBMClassifier(max_depth = 8, n_estimators = 100, min_child_samples = 100)\n",
    "lg.fit(data_train[col1].iloc[:350000].as_matrix(),data_train.label[:350000])\n",
    "#        eval_set = [(data_train.iloc[350000:410000,2:].as_matrix(),data_train.label[350000:410000])],\n",
    "#        eval_metric =score,\n",
    "#        verbose = 10)\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def score(y,pred):\n",
    "#     precesion = (pred[y == 1] > 0.5)/len(pred)\n",
    "    a = pred > 0.5\n",
    "    recall = recall_score(y,pred)\n",
    "    return 'self',recall,True\n",
    "\n",
    "score(data_train.label[350000:], res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res = lg.predict(unlabel[unlabel.date<20171001][col1].as_matrix())\n",
    "# res = lg.predict(data_train[col1].iloc[350000:].as_matrix())\n",
    "# res[data_train.label[350000:] == 1].sum()\n",
    "# res.sum()\n",
    "# data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=8, min_child_samples=100,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lg = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg.fit(data_train[col1].as_matrix(), data_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.fillna(0)\n",
    "data_test = data_test.fillna(0)\n",
    "num_train = 10\n",
    "train = []\n",
    "for i in range(num_train):\n",
    "    train.append(data_train.iloc[i*100000:i*100000+100000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "\n",
    "lg = []\n",
    "res = []\n",
    "for i in range(num_train):\n",
    "    lg.append(lgb.LGBMClassifier( max_depth = 8,  n_estimators = 100,  min_child_samples=100))\n",
    "    lg[i].fit(train[i][col].as_matrix(),train[i]['label'])\n",
    "    res.append(lg[i].predict_proba(data_test[col].as_matrix())[:,1])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "col.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = []\n",
    "res = []\n",
    "\n",
    "for i in range(num_train):\n",
    "    rf.append(RandomForestClassifier(max_depth = 8,n_estimators = 30))\n",
    "    rf[i].fit(train[i][col1].as_matrix(),train[i]['label'])\n",
    "    res.append(rf[i].predict_proba(data_test[col1].as_matrix())[:,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94731, 320)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[9].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from mlxtend.classifier import StackingClassifier \n",
    "\n",
    "\n",
    "lg = []\n",
    "rf = []\n",
    "lr = []\n",
    "xgbmodel = []\n",
    "res = []\n",
    "\n",
    "\n",
    "for i in range(num_train):\n",
    "    lg.append(lgb.LGBMClassifier(max_depth = 8, n_estimators = 100))\n",
    "#     rf.append(RandomForestClassifier(max_depth = 8, n_estimators = 30))\n",
    "    xgbmodel.append(xgb.XGBClassifier(max_depth = 8, n_estimators = 30))\n",
    "#     lr.append(LogisticRegression(C = 1.0))\n",
    "clf = []\n",
    "for i in range(num_train):\n",
    "#     clf.append( StackingClassifier(classifiers=[lg[i], xgbmodel[i]], \n",
    "#                           average_probas=False,  \n",
    "\n",
    "#                           meta_classifier=lr[i])) \n",
    "      clf.append(VotingClassifier(estimators = [('lg',lg[i]), ('xgb',xgbmodel[i])], voting = 'soft'))\n",
    "      clf[i].fit(train[i][col1].as_matrix(),train[i]['label'])\n",
    "#       append(clf[i].predict_proba(data_test[col1].as_matrix())[:,1])\n",
    "      res.append(clf[i].predict_proba(data_test[col1].as_matrix())[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "lg1 = []\n",
    "res = []\n",
    "for i in range(10):\n",
    "    lg1.append(lgb.LGBMClassifier(max_depth = 8, n_estimators = 100))\n",
    "    lg1[i].fit(train[i][col1].as_matrix(),train[i]['label'])\n",
    "    res.append(lg1[i].predict_proba(data_test[col1].as_matrix())[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\python\\venv\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[data_train.date == 20170918][data_train.label == 1].f161.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "def score(y,pred): \n",
    "    fpr, tpr, thresholds = roc_curve(y, pred, pos_label=1) \n",
    "    score1=0.4*tpr[np.where(fpr>=0.001)[0][0]]+0.3*tpr[np.where(fpr>=0.005)[0][0]]+0.3*tpr[np.where(fpr>=0.01)[0][0]] \n",
    "    return 'selfeval',score1, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-21814f27a672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:/workspace/mayi/timeline_giveup240.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "end = pd.DataFrame({'id': data_test['id'],'score':sum(res)/10})\n",
    "end.to_csv(\"D:/workspace/mayi/timeline_giveup240.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-643c99d5357c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfea_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'feature'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcol1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"imp\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'imp'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfea_im\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "fea_im = pd.DataFrame({'feature':col1, \"imp\":clf[5].feature_importances_}).sort_values(by = 'imp', ascending = False)\n",
    "                                                                            \n",
    "fea_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-565d1719f176>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20170905\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20170931\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m12000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for i in range(20170905,20170931):\n",
    "    data = pd.concat([data, data_train[data_train.date == i][data_train.f5.notnull()].iloc[:12000]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6be62cc2a3e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# for i in range(num_train):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#     res[i] = clf[i].predict_proba(unlabel[col1].as_matrix())[:,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "(sum(res)/10 > 0.5).sum()\n",
    "# for i in range(num_train):\n",
    "#     res[i] = clf[i].predict_proba(unlabel[col1].as_matrix())[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
